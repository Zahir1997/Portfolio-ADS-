# Portfolio Zahir Bholai 19126778 Applied Data Science
Lecturers: Tony Andrioli, Raymond Hoogendoorn, Ruud Vermeij and Jeroen Vuurens

## Introduction
This is the personal portfolio of a public administration student following the minor Applied Data Science. A challenging yet insightful minor for everyone who is interested in the world of data science.   

## Datacamp Courses
![Datacamp](Images/Datacamp.PNG)

## Reflection and evaluation

### Reflection on own contribution to the project.
Situation:

The Smart Teddy Project was the first data science project I participated in. I have positive memories of the project group I participated in. From day 1 we started of the project by exchanging socials and discussing ways to keep track of the project. Since my major is public administration (Bestuurskunde/Overheidsmanagement) I was a bit worried about my contribution to the project. I had moments at the beginning of the minor where I questioned myself if I am capable of completing this minor. But by staying motivated, asking questions and the will to learn I have managed to make contributions to the project. 

Task:

One of the challenging contribution I had was to classify and evaluate positive and negative emotions for the machine learning models and CNN model we had made. I had to preprocess the emotions through speech audio from the datasets in to a positive and negative classification. Then I had to run it with the machine learning models we had made. After the runs I had to evaluate the results of the positive and negative classification. The contributions I had made were in the beginning more towards the research part of the project. But when I got familiar with programming I have made some contributions towards the technical part of the project.

Action:

By asking questions at the daily stand-ups and sharing my screen with the project members to ask for help. Websites like StackOverflow and TowardsDataScience were also helpful to gain information about the contributions I worked on. 

Result:

I am happy with the results we accomplished. The group as whole were helpful towards each other. If someone was having a hard time with the contribution he was working on, a project member jumped in to help. At the end of the day the challenging contribution I faced had come to a success.

Reflection:

The lesson I have learned was to always be open about the progress you made. Four project members are studying software engineer and got much more experience than I do in the field of computer sciences. Since I am aware that my programming skills are not so well-polished as the four project members I had to ask for help at some moments when things aren’t going that well. But when I shared my screen and was looking with a project member together I got some helpful feedback to get the job done. Openness about the work you are doing was the key factor to made your contribution to the project a success.


### Reflection on own learning objectives.
Situation:

There was a reason why me, a public administration student had chosen this minor. I wanted to dive in the world of data science so I can implement the tools and methods that i am going to learn in my future career at the public sector. I have set up some learning objectives in the minor. These learning objectives I wanted to be able to do at the end of the minor.

Task:

The learning objectives what I wanted to learn are the following:
1.	I want to learn the basics of python 
2.	I want to learn how to implement a working machine learning model on a dataset
3.	I want to increase my research capabilities by learning more about visualization
4.	I want to learn how to implement a working neural network on a dataset

Action:

To reach the learning objectives I have set myself I did the following:

As a public administration student I didn’t know any programming languages. I was determined at the start of the minor to learn myself the basics of python since it was the programming language the minor was using. 
I learned about machine learning models at DataCamp and the lectures from Jeroen Vuurens.
I wanted to increase my research capabilities by learning more about data visualization. The workshops of Tony Andrioli were helpful in that matter. The do’s and don’t of data visualization were helpful. 
To implement a working neural network I have followed the lectures of Jeroen Vuurens. 

Result:

I have given whatever it takes to fulfill my learning objectives and with success. The learning objectives I have set have all been addressed in the minor. For learning the basics of python I have achieved 100% completion of the courses from DataCamp. For implementing machine learning models on datasets I have trained various machine learning models such as a SVM,  a linear regression model and a decisiontreeclassifier on various dataset from sklearn and Kaggle. I have learned about the python package Matplotlib.pyplot to create visualizations from data. Matplotlib.pyplot is something I am taking with me for the rest of my study career and future career. And for the neural network learning objective I have implemented a feed forward neural network and a convolutional network on the MNIST dataset.

Reflection:

I am satisfied with the results I have achieved in such short notice. I came to this minor with zero knowledge about python, machine learning models, neural networks and data visualization techniques. During this minor I have given whatever it takes to complete my learning objectives. I realized that I am not done learning yet. I am going to keep  training my data science skills.

### Evaluation on the group project as a whole.
Situation:

The group I participated in consist of six members including me in total. Four group members are studying software engineering and one student is studying business administration. We were all students that had to finish a minor to enter the graduation phases of our studies.  

Task:

Every group member was motivated to complete the minor. From day 1 we started with the planning of the project. Communication with the group was also excellent. From day 1 we decided what social platform we are going to use to communicate. One software engineer student is also a teacher at The Hague University of Applied Sciences so he made sure that classrooms were reserved when we are meeting at school. Another software engineer student was the scrum master of the project. He held the overview of the project and organized the daily standups, refinements and retrospectives. Everybody did their contributions to the project in the form of user stories in GitHub.

Action:

In some scenarios we would work all focus on one thing. Take for example the literature research, in the beginning of the project we have researched and discussed various papers to gain domain knowledge. In some scenarios we would work independently on our contributions. Take for example  writing the research proposal me and the business administration student worked on. In some scenarios we would be pair programming. For example, me and Jaap would be working together to train and evaluate a logistic regression model. When a group member was stuck on a contribution, another group member would jump in to help. We all were eager to get the job done even when we faced setbacks. When we faced setbacks we would discuss them on school to brainstorm for a solution. The lecturers were also helpful to guide us when we faced setbacks.

Result:

I am happy with the results we have accomplished. The group members were motivated from start to finish of the project and that shows in the final result. Everybody had made a contribution to the project.

Reflection:

I have enjoyed my first data science project with the group I was in. Everybody did what they had to do and was open about it by giving a heads-up during the daily stand-ups. After the sprint we had a retrospective where we would discuss the good aspects of the current sprint, bad aspects of the current sprint and action points for the next sprint. I enjoyed this structured way of working. 
  
## Research Project

### Task Definition
The Smart Teddy is a therapeutic companion with a very basic functionality. It can bark and move its tail if someone interacts with it. It is soft and cuddly to invite people to grab and hug it. Seniors can keep the Smart Teddy as a long term companion. Like a real pet, the Smart Teddy observes the senior citizen using its sensors. It has a digital brain that allows it to understand what the senior does during the day and estimates how much the senior citizen is enjoying his/her time. Teddy can also check whether the senior is having enough sleep and how often they wake up during the night. From all this information, Teddy tries to make an educated guess about the QoL of the senior, and inform their family or caregivers about their condition. 

The Smart Teddy project were split into three groups in this minor, one group worked on detecting eating and drinking sounds and another group worked on detecting dialogue in the room. Our research group was assigned to work on the emotions part of this whole project led by dr. Hani Al – Ers. The end goal of our assigned project was to detect and classify emotions the dementia patient was showing. After discussing with our product owner and lectureres we had come up with the following main research question:

Which machine learning models achieve the highest precision classifying emotions, using (two) datasets containing audio with labeled vocal emotional expressions recorded in a professional recording studio, in order to recognize emotions within household environments?

More information about the main research question will be covered in the research proposal sub-chapter.

#### Research proposal
The research proposal was written by myself and project member Breno van Tricht. We have written the research propsal to get a clear view of the research we are going to conduct and it also has been of aid at writing the research paper. The reason that the research main question was chosen, was because the research group were investigating the current methods of classifying emotions from audio data. After investigating these methods the research group make a choice for the best looking model and will train it on the emotion-labelled datasets that we have found. Aiming for the highest precision was chosen because the end use involves mental health regarding dementia which must be handled with care. It's unacceptable to have a lot of false positives because the teddy bear is used as an advisor and the professionals can decide how to respond to this. It is better to be certain of an emotion than to misclassify an emotion. The emotions detected and shown are an indication of how the patient is feeling and if he is capable of living on his own. 
The scope of the research, sub-questions, evaluation method, and related work are also covered in the 
[research proposal](https://docs.google.com/document/d/1NxFVP1G9DyZr4Q7_GdJvULewCiscxtOvygtyHUCDSeE/edit#heading=h.rqlgrsn8oj5p).

#### Notes
Every week the research group had meetings with lectureres and the product owner. New ideas and feedback are some of the many things that are discussed at the meetings. At these meetings I functioned as a note taker to have the topics that are discussed written down so that the research group won't forget it. The [notes](https://docs.google.com/document/d/1xQncillbnLcRF8wKagUnnbbejlcOvx4zWCJvwhQ0PGc/edit#) are here.


### Evaluation

### Conclusions

### Planning

## Predictive Analytics

### Selecting a Model

The machine learning models the group have worked on to make predictions are: SVM, logistic regression, multi-layered perceptron and a KNN model.
Me and Jaap have worked on a logistic regression model to make predictions. Since we didn't have acces to real world data for the project we used datasets containing vocal audio samples spoken in different emotions. We have chosen this model because in our literature study we came across a [paper](https://ieeexplore-ieee-org.ezproxy.hhs.nl/stamp/stamp.jsp?tp=&arnumber=9249147) that used a logistic regression model to make predictions on one of the datasets (RAVDESS) we are using. We were interested in what the results would be for both datasets we used. We have used the RAVDESS and CREMA-D datasets  

### Configuring a Model
For the configuration of the logistic regression model we have used all hyperparameters that we could [find](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). 
    
    class LogisticalRegression(BaseModel):
    instance = "Logistical Regression"
    
    @classmethod
    def grid_search(self,model,x_train, x_test, y_train, y_test,scoring):
        
        solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']
        penalty = ['none', 'l1','l2','elasticnet']
        param_grid = dict(solver=solvers,penalty=penalty,C=c_values)
            
       

### Training a model

To prevent to model for overfitting and underfitting we have used GridSearchCV. What GridsearchCV basically does is to find the best hyperparameters for you to fit it a model you are using. That is the reason why we have chosen all hyperparameters from the logistic regression model since GridsearchCV will search for the best hyperparameters the model has to offer.

        start_time = time.perf_counter()
        clf = GridSearchCV(model, param_grid, cv=5, scoring=scoring, n_jobs=5) 
        end_time = time.perf_counter()
        print(f"Duration Gridsearch: {end_time - start_time:04f}")
        
        start_time = time.perf_counter()
        clf.fit(x_train, y_train)
        end_time = time.perf_counter()
        
        print(f"Duration fitting: {end_time - start_time:04f}")
        print()
        
        print("Best parameters set found on development set:")
        print(clf.best_params_)
        print(clf.best_estimator_)

        super().model_accuracy(clf, x_train, x_test, y_train, y_test)
        
I have tweaked the cv parameter a bit to see if there are any changes in the train and test accuracy. I have noticed that there is a minimal positive change in train and test accuracy when you change the cv parameter to an even variable and a minimal negative change when you change it to an uneven variable.

| First Header  | Second Header |
| ------------- | ------------- |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |

### Evaluating a model

We have evaluated the logistic regression model with the other machine learning models the group members have made. 

| First Header  | Second Header | Third Header  |   
| ------------- | ------------- | ------------- | 
| Content Cell  | Content Cell  | Content Cell  |
| Content Cell  | Content Cell  | Content Cell  |



 
### Visualizing the outcome of a model (explanatory)

## Domain knowledge

### Introduction of the subject field

### Literature research

### Explanation of Terminology, jargon and definitions

## Data preprocessing

### Data exploration
 
### Data cleansing

### Data preparation

### Data explanation

### Data visualization (exploratory)

## Communications

### Presentations

### Writing paper

## List of Notebooks 



